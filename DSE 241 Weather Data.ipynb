{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d167525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "#import required functions\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math\n",
    "import os\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import datetime\n",
    "from pandas import DataFrame\n",
    "import itertools\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import torch\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import re\n",
    "import spacy\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from bs4 import BeautifulSoup\n",
    "import mechanize\n",
    "import urllib.request\n",
    "import http.cookiejar as cookielib\n",
    "import requests\n",
    "from pprint import pprint\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f67c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createfiledirectory(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "    return directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383c203e",
   "metadata": {},
   "source": [
    "# **Analyze Disneyland Reviews Raw Dataset Column Attributes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b21e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "username='joythompson'\n",
    "projdir=\"/Users/\"+username+\"/Desktop/DSE241_FinalProject_JoyT/\"\n",
    "tabraw=createfiledirectory(projdir + 'PreprocessedData/')\n",
    "tabready=createfiledirectory(projdir + 'ProcessedTableauReady/')\n",
    "\n",
    "reviews=pd.read_csv('https://github.com/JoyT10294/DSE241_FinalProject_JoyT/blob/main/PreprocessedData/DisneylandReviews.csv')\n",
    "print(reviews)\n",
    "numofregion=len(reviews.groupby(['Reviewer_Location']).count().reset_index())\n",
    "maxrevlen=0\n",
    "maxloclen=0\n",
    "minrevlen=500\n",
    "minloclen=5\n",
    "for ind in reviews.index:\n",
    "    if len(str(reviews.loc[ind, 'Review_Text']))>maxrevlen:\n",
    "        maxrevlen=len(str(reviews.loc[ind, 'Review_Text']))\n",
    "    elif len(str(reviews.loc[ind, 'Review_Text']))!=0 and len(str(reviews.loc[ind, 'Review_Text']))<minrevlen:\n",
    "        minrevlen=len(str(reviews.loc[ind, 'Review_Text']))\n",
    "    if len(str(reviews.loc[ind, 'Reviewer_Location']))>maxloclen:\n",
    "        maxloclen=len(str(reviews.loc[ind, 'Reviewer_Location']))\n",
    "    elif len(str(reviews.loc[ind, 'Reviewer_Location']))!=0 and len(str(reviews.loc[ind, 'Reviewer_Location']))<minloclen:\n",
    "        minloclen=len(str(reviews.loc[ind, 'Reviewer_Location']))\n",
    "print('# of Unique Countries: '+str(numofregion)+' Max Char Review Text: '+str(maxrevlen)+' Max Char Location: '+\n",
    "      str(maxloclen)+' Min Char Review Text: '+str(minrevlen)+' Min Char Location: '+str(minloclen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae2eba0",
   "metadata": {},
   "source": [
    "# **Extract Monthly Temperature & Humidity Historical Data from Timeanddate.com for All Branch Locations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de569ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getweatherdata(linkloc, branchdata, country):  \n",
    "    for year in range(2010, 2020):\n",
    "        for month in range(1, 13):\n",
    "            month=str(month)\n",
    "            year=str(year)\n",
    "            url=linkloc + month + '&year='+ year\n",
    "            response =urllib.request.Request(url)\n",
    "            result = urllib.request.urlopen(response)\n",
    "            resulttext = result.read()\n",
    "            soup = BeautifulSoup(resulttext)\n",
    "            for script in soup([\"script\", \"style\"]):\n",
    "                script.extract()    # rip it out\n",
    "            text = soup.get_text()\n",
    "            lines = (line.strip() for line in text.splitlines())\n",
    "            chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "            text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "            temptext=text.split('TemperatureHumidityPressureHigh')[1].split('Reported')[0]\n",
    "            temphigh=temptext.split('째')[0]\n",
    "            humidhigh=temptext.split(')')[1].split('%')[0]\n",
    "            templow=temptext.split('Low')[1].split('째')[0]\n",
    "            humidlow=temptext.split('Low')[1].split(')')[1].split('%')[0]\n",
    "            tempavg=temptext.split('Average')[1].split('째')[0]\n",
    "            humidavg=temptext.split('Average')[1].split('째F')[1].split('%')[0]\n",
    "            if int(year)>2010 or int(month)>9:\n",
    "                branchdata=branchdata.append({'location':country, 'month':month, 'year':year,'temp_high':temphigh, 'temp_low':templow, 'temp_average':tempavg,\n",
    "                                          'humid_high':humidhigh,  'humid_low':humidlow, 'humid_average':humidavg}, ignore_index=True)\n",
    "    return branchdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4cca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "branchdata=pd.DataFrame(columns=['location','month', 'year' 'temp_high', 'temp_low', 'temp_average', 'humid_high', 'humid_low', 'humid_average'])\n",
    "branchdata=getweatherdata('https://www.timeanddate.com/weather/france/paris/historic?month=', branchdata, 'Paris')\n",
    "branchdata=getweatherdata('https://www.timeanddate.com/weather/usa/anaheim/historic?month=', branchdata, 'Anaheim')\n",
    "branchdata=getweatherdata('https://www.timeanddate.com/weather/@1818609/historic?month=', branchdata, 'Hong Kong')\n",
    "branchdata.to_csv(tabraw+'BranchMonthlyWeatherData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab17b8d1",
   "metadata": {},
   "source": [
    "# **Append Monthly Temperature & Humidity Data According to Branch & Visit Month to Reviews Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e326965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addtemphumid(reviews, branchdata, city):  \n",
    "    data=branchdata[branchdata['location']==city].set_index('year_mon')\n",
    "    reviews.loc[ind, 'location']=city\n",
    "    reviews.loc[ind, 'temp_average']=data.loc[yearmon, 'temp_average']\n",
    "    reviews.loc[ind, 'temp_low']=data.loc[yearmon, 'temp_low']\n",
    "    reviews.loc[ind, 'temp_high']=data.loc[yearmon, 'temp_high']\n",
    "    reviews.loc[ind, 'humid_average']=data.loc[yearmon, 'humid_average']\n",
    "    reviews.loc[ind, 'humid_low']=data.loc[yearmon, 'humid_low']\n",
    "    reviews.loc[ind, 'humid_high']=data.loc[yearmon, 'humid_high']\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f01a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "branchdata=pd.read_csv(tabraw+'BranchMonthlyWeatherData.csv')\n",
    "for ind in branchdata.index:\n",
    "    branchdata.loc[ind, 'year_mon']=str(branchdata.loc[ind,'year'])+ '-'+str(branchdata.loc[ind,'month'])\n",
    "droplist=[]\n",
    "for ind in reviews.index:\n",
    "    yearmon=reviews.loc[ind, 'Year_Month']\n",
    "    if str(yearmon) in ['2010-9', '2010-8','2010-7', '2010-6', '2010-5', 'missing','2010-4','2010-3','2010-2','2010-1']:\n",
    "        droplist.append(ind)\n",
    "    elif 'Paris' in reviews.loc[ind, 'Branch']:\n",
    "        reviews=addtemphumid(reviews, branchdata, 'Paris')\n",
    "    elif 'HongKong' in reviews.loc[ind, 'Branch']:\n",
    "        reviews=addtemphumid(reviews, branchdata, 'Hong Kong')\n",
    "    elif 'California' in reviews.loc[ind, 'Branch']:\n",
    "        reviews=addtemphumid(reviews, branchdata, 'Anaheim')\n",
    "review=reviews.drop(dropd\n",
    "review.to_csv(tabready+'DisneyReviewerAppendWeatherData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02216885",
   "metadata": {},
   "source": [
    "# **Create Dataset of Top Unique Keywords/Phrases from Reviewers Comments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22286816",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "wordlabelpd=pd.DataFrame(columns=['Review_ID', 'EntityOrderID', 'Text', 'CategoryLabel']);\n",
    "for ind in review.index:\n",
    "    doc = nlp(str(review.loc[ind,'Review_Text']))\n",
    "    entorder=0;\n",
    "    for ent in doc.ents:\n",
    "        entorder=entorder+1;\n",
    "        label=ent.label_;\n",
    "        wordlabelpd=wordlabelpd.append({'Review_ID':review.loc[ind, 'Review_ID'],\n",
    "                'EntityOrderID':entorder , 'Text': str(ent.text).lower(), 'CategoryLabel': label}, ignore_index=True);\n",
    "\n",
    "uniquepd=wordlabelpd.groupby(['Text']).count().reset_index().sort_values(by=['Review_ID'], ascending=False)\n",
    "uniquepd.to_csv(tabraw+'ExtractWordsPhrasesReviewComment.csv')\n",
    "wordlabelpd.to_csv(tabraw+'CreateUniqueWordListExtractedReviewComment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aa35bf",
   "metadata": {},
   "source": [
    "# **Create Dataset of All Cases a Top Unique Keyword/Phrases Exists in a Rewiewers Comments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060af057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File uniquepd.csv manually cleaned and limited to 100 with excel to create top 100 words.csv\n",
    "#Ideally string matching & data cleaning functions should be utilized to create the top word list\n",
    "top=pd.read_csv(tabraw+'top 100 words.csv').drop(columns=['Unnamed: 0'])\n",
    "review=pd.read_csv(tabraw+'DisneyReviewerAppendWeatherData.csv')\n",
    "topwordall=pd.DataFrame(columns=['Top Word','Work Top Ranking', '# of Reviews w/Word','Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', \n",
    "       'Branch', 'location', 'temp_average', 'temp_low', 'temp_high','humid_average', 'humid_low', 'humid_high'])\n",
    "\n",
    "for ind in top.index:\n",
    "    text=top.loc[ind, 'Text']\n",
    "    for i in range(1,6):\n",
    "        top.loc[ind, 'Rating '+ str(i)]=0\n",
    "    numofrate=0\n",
    "    sumrate=0\n",
    "    for ind2 in review.index:\n",
    "        revtext=review.loc[ind2, 'Review_Text']\n",
    "        rating=review.loc[ind2, 'Rating']\n",
    "        if text in revtext:\n",
    "            topwordall=topwordall.append({'Top Word':text, '# of Reviews w/Word':top.loc[ind, '# of Reviews w/Word'],\n",
    "                                          'Work Top Ranking':ind+1, 'Review_ID': review.loc[ind2, 'Review_ID'], \n",
    "                                          'Rating':rating, 'Year_Month':review.loc[ind2, 'Year_Month'], \n",
    "                                          'Reviewer_Location':review.loc[ind2, 'Reviewer_Location'], \n",
    "                                           'Branch':review.loc[ind2, 'Branch'], 'location':review.loc[ind2, 'location'],\n",
    "                                          'temp_average':review.loc[ind2, 'temp_average'],'temp_low':review.loc[ind2, 'temp_low'], \n",
    "                                          'temp_high': review.loc[ind2, 'temp_high'],'humid_average':review.loc[ind2, 'humid_average'],'humid_low':review.loc[ind2, 'humid_low'], \n",
    "                                          'humid_high': review.loc[ind2, 'humid_high']\n",
    "                                         }, ignore_index=True)\n",
    "            numofrate=numofrate+1\n",
    "            sumrate=sumrate+rating\n",
    "            top.loc[ind, 'Rating '+ str(int(rating))]=top.loc[ind, 'Rating '+ str(int(rating))]+1\n",
    "    top.loc[ind, 'Rating Average']=np.round(sumrate/numofrate, decimals=2)\n",
    "top.to_csv(tabready+'top_100_words_with_avg_rating.csv')\n",
    "topwordall.to_csv(tabready+'top_100_words_with_all_review_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
